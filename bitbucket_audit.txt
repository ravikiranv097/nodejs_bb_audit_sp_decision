// bitbucket_audit.js

'use strict';

const fs = require('fs');
const path = require('path');
const xlsx = require('xlsx');
const axios = require('axios');
const puppeteer = require('puppeteer');
require('dotenv').config();
// const { Document, Packer, Paragraph, ImageRun } = require("docx");
const officegen = require('officegen');
let sharp = null;
try {
  sharp = require('sharp');
} catch (e) {
  console.warn('`sharp` not installed — PNG trimming will be skipped. Install with `npm install sharp` to enable trimming.');
}



// ------------------- CONFIG -------------------

const INPUT_DIR = path.join(__dirname, 'input_files');
const OUTPUT_DIR = path.join(__dirname, 'output_files');

const INPUT_XLSX = path.join(INPUT_DIR, 'SP_Decision_Sheet_Dummy.xlsx');
const REVOKED_CSV = path.join(OUTPUT_DIR, 'revoked_rows.csv');
const FORMATTED_CSV = path.join(OUTPUT_DIR, 'formatted_revoked_rows.csv');

const ACCESS_OUTPUT_CSV = path.join(OUTPUT_DIR, 'access_check_results.csv');
const NO_ACCESS_OUTPUT_CSV = path.join(OUTPUT_DIR, 'no_access_check_results.csv');
const SCREENSHOTS_DIR = path.join(OUTPUT_DIR, 'screenshots');

const HAS_ACCESS_PNG_DIR = path.join(OUTPUT_DIR, "png/has_access");
const NO_ACCESS_PNG_DIR = path.join(OUTPUT_DIR, "png/no_access");

const DOC_DIR = path.join(OUTPUT_DIR, "doc");

// Create all required directories
ensureDir(OUTPUT_DIR);
ensureDir(HAS_ACCESS_PNG_DIR);
ensureDir(NO_ACCESS_PNG_DIR);
ensureDir(DOC_DIR);

// Bitbucket API config
const BB_URL_RAW = (process.env.BB_URL || '').trim();
const USERNAME = process.env.BB_USERNAME;
const KEYNAME = process.env.BB_KEYNAME;

if (!BB_URL_RAW || !USERNAME || !KEYNAME) {
  console.error("Missing BB_URL, BB_USERNAME or BB_KEYNAME in .env");
  process.exit(1);
}

// Normalize base URL: ensure protocol and remove trailing slashes
let BASE_URL = BB_URL_RAW.replace(/\/+$/g, '');
if (!/^https?:\/\//i.test(BASE_URL)) {
  BASE_URL = 'http://' + BASE_URL;
}


// ------------------- UTILS -------------------

function ensureDir(dirPath) {
  if (!fs.existsSync(dirPath)) {
    fs.mkdirSync(dirPath, { recursive: true });
  }
}

// Trim helper (like xargs in bash)
function trim(value) {
  return String(value || '').trim();
}

// Format timestamp: equivalent to `date "+%Y-%m-%d %H:%M:%S"`
function formatTimestamp() {
  const d = new Date();
  const pad = (n) => String(n).padStart(2, '0');
  const yyyy = d.getFullYear();
  const mm = pad(d.getMonth() + 1);
  const dd = pad(d.getDate());
  const hh = pad(d.getHours());
  const mi = pad(d.getMinutes());
  const ss = pad(d.getSeconds());
  return `${yyyy}-${mm}-${dd} ${hh}:${mi}:${ss}`;
}

// Safe timestamp for filenames: equivalent to `date "+%Y-%m-%d_%H-%M-%S"`
function formatSafeTimestamp() {
  const d = new Date();
  const pad = (n) => String(n).padStart(2, '0');
  const yyyy = d.getFullYear();
  const mm = pad(d.getMonth() + 1);
  const dd = pad(d.getDate());
  const hh = pad(d.getHours());
  const mi = pad(d.getMinutes());
  const ss = pad(d.getSeconds());
  return `${yyyy}-${mm}-${dd}_${hh}-${mi}_${ss}`;
}

// Simple CSV row builder (no quoting, to stay close to your shell output)
function csvRow(fields) {
  return fields.map((f) => String(f ?? '').replace(/\r?\n/g, ' ')).join(',');
}


// ------------------- REDACTION UTILS -------------------

// Shallow redacter for Bitbucket-like API responses.
// Keeps the structure but removes obvious PII/secret-looking fields.
// This is intentionally conservative — adjust keys based on real API shapes.
function redactSensitiveFields(obj) {
  if (!obj) return obj;
  try {
    const clone = JSON.parse(JSON.stringify(obj));

    // Example: entries under `values` often contain user objects
    if (Array.isArray(clone.values)) {
      clone.values = clone.values.map((v) => {
        if (v && typeof v === 'object') {
          // If there's a nested user object
          if (v.user && typeof v.user === 'object') {
            if (v.user.emailAddress) v.user.emailAddress = '[REDACTED_EMAIL]';
            if (v.user.name) v.user.name = '[REDACTED_NAME]';
            if (v.user.displayName) v.user.displayName = '[REDACTED_DISPLAYNAME]';
            if (v.user.slug) v.user.slug = '[REDACTED]';
            if (v.user.password) v.user.password = '[REDACTED]';
            if (v.user.accessToken) v.user.accessToken = '[REDACTED]';
          }

          // Mask common token/secret fields at the value level
          const fieldsToMask = ['token', 'password', 'secret', 'accessToken', 'refreshToken', 'credentials'];
          fieldsToMask.forEach((k) => {
            if (v[k]) v[k] = '[REDACTED]';
          });
        }
        return v;
      });
    }

    // Top-level user object handling
    if (clone.user && typeof clone.user === 'object') {
      if (clone.user.emailAddress) clone.user.emailAddress = '[REDACTED_EMAIL]';
      if (clone.user.displayName) clone.user.displayName = '[REDACTED_DISPLAYNAME]';
    }

    // Generic top-level masking
    const topKeysToMask = ['password', 'token', 'secret', 'accessToken', 'refreshToken', 'credentials'];
    topKeysToMask.forEach((k) => {
      if (clone[k]) clone[k] = '[REDACTED]';
    });

    return clone;
  } catch (e) {
    // If cloning fails for any reason, return a minimal safe fallback
    return { note: '[REDACTED: unable to parse response]' };
  }
}


// ------------------- STEP 1 + 2: XLSX -> revoked_rows.csv -------------------

function extractRevokedRowsFromXlsx() {
  console.log('Step 1 & 2: Reading XLSX and extracting revoked rows...');

  if (!fs.existsSync(INPUT_XLSX)) {
    throw new Error(`Input XLSX not found at: ${INPUT_XLSX}`);
  }

  const workbook = xlsx.readFile(INPUT_XLSX);
  const firstSheetName = workbook.SheetNames[0];
  const worksheet = workbook.Sheets[firstSheetName];

  // Convert sheet to JSON, first row as headers
  const rows = xlsx.utils.sheet_to_json(worksheet, { defval: '' });

  if (rows.length === 0) {
    console.warn('No data found in XLSX file.');
  }

  // Header keys in order
  const header = rows.length > 0 ? Object.keys(rows[0]) : [];

  // Filter rows where Decision == "Revoked"
  const revokedRows = rows.filter(
    (r) => trim(r['Decision']) === 'Revoked'
  );

  // Write revoked_rows.csv (header + revoked rows)
  ensureDir(OUTPUT_DIR);
  const lines = [];
  if (header.length > 0) {
    lines.push(csvRow(header));
    for (const row of revokedRows) {
      const fields = header.map((h) => row[h] ?? '');
      lines.push(csvRow(fields));
    }
  }

  fs.writeFileSync(REVOKED_CSV, lines.join('\n'), 'utf8');

  console.log('Extraction completed.');
  console.log(`Filtered rows saved to: ${REVOKED_CSV}`);

  return revokedRows;
}

// ------------------- STEP 3: revoked_rows.csv -> formatted_revoked_rows.csv -------------------

function transformRevokedRowsToFormatted(revokedRows) {
  console.log('Step 3: Transforming revoked rows to formatted_revoked_rows.csv...');

  // Header as per your shell script
  const header = ['User SSO', 'Account ID', 'Project Key', 'Access Permission', 'Decision'];
  const lines = [csvRow(header)];

  for (const row of revokedRows) {
    const user_sso = trim(row['User SSO']);
    const account_id = trim(row['Account ID']);
    const entitlement_desc = trim(row['Entitlement Description']);
    const decision = trim(row['Decision']);

    // Example entitlement_desc: "P : PB-Admin"
    let project_key = '';
    let access_permission = '';

    if (entitlement_desc) {
      // Split on ':'
      const colonParts = entitlement_desc.split(':');
      if (colonParts[1]) {
        const rightSide = colonParts[1].trim(); // e.g. "PB-Admin"
        const dashParts = rightSide.split('-');
        project_key = trim(dashParts[0]);       // e.g. "PB"
        access_permission = trim(dashParts[1]); // e.g. "Admin"
      }
    }

    lines.push(csvRow([user_sso, account_id, project_key, access_permission, decision]));
  }

  fs.writeFileSync(FORMATTED_CSV, lines.join('\n'), 'utf8');

  console.log('Transformation complete.');
  console.log(`Output saved to ${FORMATTED_CSV}`);
}


// ------------------- STEP 4: Bitbucket access check + screenshots -------------------

async function performAccessCheck() {
  console.log('Step 4: Performing Bitbucket access check...');

  const HTML_DIR = path.join(OUTPUT_DIR, 'html');

  ensureDir(HTML_DIR);
  ensureDir(HAS_ACCESS_PNG_DIR);
  ensureDir(NO_ACCESS_PNG_DIR);

  fs.writeFileSync(
    ACCESS_OUTPUT_CSV,
    csvRow([
      'Username',
      'Account ID',
      'Project Key',
      'Access Permission',
      'Access Status',
      'Timestamp',
      'Screenshot File',
    ]) + '\n'
  );

  fs.writeFileSync(
    NO_ACCESS_OUTPUT_CSV,
    csvRow([
      'Username',
      'Account ID',
      'Project Key',
      'Access Permission',
      'Access Status',
      'Timestamp',
      'Screenshot File'
    ]) + '\n'
  );

  const content = fs.readFileSync(FORMATTED_CSV, 'utf8');
  const rows = content.split(/\r?\n/).filter((l) => l.trim());
  if (rows.length <= 1) return;

  let browser = null;
  let page = null;

  async function getBrowserPage() {
    if (!browser) {
      browser = await puppeteer.launch({ headless: true });
      page = await browser.newPage();
    }
    return page;
  }

  for (let i = 1; i < rows.length; i++) {
    const [user_sso, account_id, project_key, access_permission] =
      rows[i].split(',').map(trim);

    const api_url = `${BASE_URL}/rest/api/1.0/projects/${encodeURIComponent(project_key)}/permissions/users?filter=${encodeURIComponent(
      user_sso
    )}`;

    let responseData;
    try {
      const resp = await axios.get(api_url, {
        auth: { username: USERNAME, password: KEYNAME },
      });
      // redact sensitive fields before storing/writing to HTML/PNG
      responseData = redactSensitiveFields(resp.data);
    } catch {
      responseData = { values: [] };
    }

    const has_access = Array.isArray(responseData.values)
      ? responseData.values.length > 0
      : false;

    const ts = formatTimestamp();
    const safe_ts = formatSafeTimestamp();

    const htmlFile = path.join(
      HTML_DIR,
      `${user_sso}_${project_key}_${safe_ts}.html`
    );

    const html = `
<html>
<head>
  <meta charset="utf-8" />
    <style>
    html, body { margin: 0; padding: 0; background: #ffffff; }
    #evidence { font-family: monospace; padding: 0; margin: 0; display: inline-block; box-sizing: border-box; }
    h2, h3 { margin: 6px 0; }
    p { margin: 4px 0; }
    /* Make pre shrink-wrap so long JSON won't force wide layout */
    pre { display: inline-block; margin: 0; white-space: pre-wrap; word-break: break-word; max-width: 1200px; }
    /* Remove forced min-width on labels to avoid extra horizontal space */
    b { display: inline-block; }
  </style>
</head>
<body>
  <div id="evidence">
    <div><b>User:</b> ${user_sso}</div>
    <div><b>Project:</b> ${project_key}</div>
    <div><b>Timestamp:</b> ${ts}</div>
    <h3>REST API URL</h3>
    <p>${api_url}</p>
    <h3>API Response <small style="font-weight:normal;color:#666">[REDACTED]</small></h3>
    <pre>${JSON.stringify(responseData, null, 2)}</pre>
  </div>
</body>
</html>`;

    fs.writeFileSync(htmlFile, html);

    const pageIns = await getBrowserPage();
    await pageIns.goto('file://' + htmlFile, { waitUntil: 'networkidle0' });

    const requiredHeight = await pageIns.evaluate(() => document.body.scrollHeight);
    await pageIns.setViewport({ width: 1280, height: requiredHeight });

    // SELECT PNG DIRECTORY BASED ON ACCESS
    const pngFile = has_access
      ? path.join(HAS_ACCESS_PNG_DIR, `${user_sso}_${project_key}_${safe_ts}.png`)
      : path.join(NO_ACCESS_PNG_DIR, `${user_sso}_${project_key}_${safe_ts}.png`);

    const tmpPng = pngFile + '.tmp.png';
    // Capture full page to temp file and then trim uniform borders using sharp
    try {
      await pageIns.screenshot({ path: tmpPng, fullPage: true });
    } catch (e) {
      // If fullPage not supported/fails, fallback to viewport screenshot
      await pageIns.screenshot({ path: tmpPng });
    }

    if (sharp) {
      try {
        // Load raw pixels to compute tight bounding box of non-white content
        const { data, info } = await sharp(tmpPng).ensureAlpha().raw().toBuffer({ resolveWithObject: true });
        const w = info.width; const h = info.height; const c = info.channels; // channels includes alpha
        const threshold = 200; // consider pixels darker than near-white as content (tighter)

        let minX = w, minY = h, maxX = 0, maxY = 0;
        for (let y = 0; y < h; y++) {
          for (let x = 0; x < w; x++) {
            const idx = (y * w + x) * c;
            // check RGB channels (ignore alpha)
            const r = data[idx];
            const g = data[idx+1];
            const b = data[idx+2];
            if (r < threshold || g < threshold || b < threshold) {
              if (x < minX) minX = x;
              if (x > maxX) maxX = x;
              if (y < minY) minY = y;
              if (y > maxY) maxY = y;
            }
          }
        }

        if (minX <= maxX && minY <= maxY) {
          // Add a small outer padding so the PNG has some breathing room
          const OUTER_PAD = 8; // pixels on each side
          minX = Math.max(0, minX - OUTER_PAD);
          minY = Math.max(0, minY - OUTER_PAD);
          maxX = Math.min(w - 1, maxX + OUTER_PAD);
          maxY = Math.min(h - 1, maxY + OUTER_PAD);

          const extractW = maxX - minX + 1;
          const extractH = maxY - minY + 1;
          await sharp(tmpPng).extract({ left: minX, top: minY, width: extractW, height: extractH }).toFile(pngFile);
          fs.unlinkSync(tmpPng);
        } else {
          // nothing detected, fallback to trim
          await sharp(tmpPng).trim().toFile(pngFile);
          fs.unlinkSync(tmpPng);
        }
      } catch (e) {
        try { fs.renameSync(tmpPng, pngFile); } catch (_) { /* ignore */ }
      }
    } else {
      try { fs.renameSync(tmpPng, pngFile); } catch (_) { /* ignore */ }
    }

    // LOG CSV
    if (has_access) {
      fs.appendFileSync(
        ACCESS_OUTPUT_CSV,
        csvRow([
          user_sso,
          account_id,
          project_key,
          access_permission,
          'HAS_ACCESS',
          ts,
          pngFile,
        ]) + '\n'
      );
    } else {
      fs.appendFileSync(
        NO_ACCESS_OUTPUT_CSV,
        csvRow([
          user_sso,
          account_id,
          project_key,
          access_permission,
          'NO_ACCESS',
          ts,
          pngFile
        ]) + '\n'
      );
    }
  }

  if (browser) await browser.close();

  console.log('✔ Access verification complete');
}

// ------------------- Generate DOCX with screenshots -------------------

async function generateDoc(hasAccessDir, outputFileName) {
  console.log(`Generating DOCX → ${outputFileName}`);

  const images = fs.readdirSync(hasAccessDir).filter(f => f.endsWith(".png"));
  if (images.length === 0) {
    console.log(`No screenshots found in ${hasAccessDir}`);
    return;
  }

  const docx = officegen("docx");

  docx.on("error", console.error);

  let p = docx.createP({ align: "center" });
  p.addText(outputFileName.replace(".docx", ""), { bold: true, font_size: 28 });

  docx.createP();
  docx.createP({ align: "center" }).addText(
    `Generated: ${new Date().toLocaleString()}`,
    { font_size: 14 }
  );

  docx.createP().addText("", { pageBreakBefore: true });

  images.forEach((file, idx) => {
    const filePath = path.join(hasAccessDir, file);

    let imgP = docx.createP({ align: "center" });
    imgP.addImage(filePath);

    if (idx < images.length - 1) {
      docx.createP().addText("", { pageBreakBefore: true });
    }
  });

  const outPath = path.join(DOC_DIR, outputFileName);
  const out = fs.createWriteStream(outPath);

  return new Promise((resolve, reject) => {
    out.on("error", reject);
    out.on("close", () => {
      console.log(`✔ DOCX generated → ${outPath}`);
      resolve();
    });
    docx.generate(out);
  });
}



// ------------------- MAIN -------------------

async function main() {
  ensureDir(INPUT_DIR);
  ensureDir(OUTPUT_DIR);

  // Step 1 & 2: XLSX -> revoked_rows.csv
  const revokedRows = extractRevokedRowsFromXlsx();

  // Step 3: revoked_rows.csv -> formatted_revoked_rows.csv
  transformRevokedRowsToFormatted(revokedRows);

  // Step 4: access check via Bitbucket API + screenshots
  await performAccessCheck();

  // Generate DOC with screenshots
    await generateDoc(HAS_ACCESS_PNG_DIR, "Bitbucket_Has_Access_Report.docx");
    await generateDoc(NO_ACCESS_PNG_DIR, "Bitbucket_No_Access_Report.docx");

}

main().catch((err) => {
  console.error('Error running Bitbucket audit script:', err);
  process.exit(1);
});
